{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Demo.csv', error_bad_lines=False, encoding = 'unicode_escape');\n",
    "data_text = data[['tweet']]\n",
    "data_text['index'] = data_text.index\n",
    "documents = data_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4006"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @rssurjewala: Critical question: Was PayTM ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @Hemant_80: Did you vote on #Demonetization...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @roshankar: Former FinSec, RBI Dy Governor,...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @ANI_news: Gurugram (Haryana): Post office ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @satishacharya: Reddy Wedding! @mail_today ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  index\n",
       "0  RT @rssurjewala: Critical question: Was PayTM ...      0\n",
       "1  RT @Hemant_80: Did you vote on #Demonetization...      1\n",
       "2  RT @roshankar: Former FinSec, RBI Dy Governor,...      2\n",
       "3  RT @ANI_news: Gurugram (Haryana): Post office ...      3\n",
       "4  RT @satishacharya: Reddy Wedding! @mail_today ...      4"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original word</th>\n",
       "      <th>stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>caresses</td>\n",
       "      <td>caress</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>flies</td>\n",
       "      <td>fli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dies</td>\n",
       "      <td>die</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mules</td>\n",
       "      <td>mule</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>denied</td>\n",
       "      <td>deni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>died</td>\n",
       "      <td>die</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>agreed</td>\n",
       "      <td>agre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>owned</td>\n",
       "      <td>own</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>humbled</td>\n",
       "      <td>humbl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sized</td>\n",
       "      <td>size</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>meeting</td>\n",
       "      <td>meet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>stating</td>\n",
       "      <td>state</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>siezing</td>\n",
       "      <td>siez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>itemization</td>\n",
       "      <td>item</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>sensational</td>\n",
       "      <td>sensat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>traditional</td>\n",
       "      <td>tradit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>reference</td>\n",
       "      <td>refer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>colonizer</td>\n",
       "      <td>colon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>plotted</td>\n",
       "      <td>plot</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   original word stemmed\n",
       "0       caresses  caress\n",
       "1          flies     fli\n",
       "2           dies     die\n",
       "3          mules    mule\n",
       "4         denied    deni\n",
       "5           died     die\n",
       "6         agreed    agre\n",
       "7          owned     own\n",
       "8        humbled   humbl\n",
       "9          sized    size\n",
       "10       meeting    meet\n",
       "11       stating   state\n",
       "12       siezing    siez\n",
       "13   itemization    item\n",
       "14   sensational  sensat\n",
       "15   traditional  tradit\n",
       "16     reference   refer\n",
       "17     colonizer   colon\n",
       "18       plotted    plot"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer = SnowballStemmer('english')\n",
    "original_words = ['caresses', 'flies', 'dies', 'mules', 'denied','died', 'agreed', 'owned', \n",
    "           'humbled', 'sized','meeting', 'stating', 'siezing', 'itemization','sensational', \n",
    "           'traditional', 'reference', 'colonizer','plotted']\n",
    "singles = [stemmer.stem(plural) for plural in original_words]\n",
    "pd.DataFrame(data = {'original word': original_words, 'stemmed': singles})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_stemming(text):\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Previewing preprocessor funct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original document: \n",
      "['RT', '@ModiBharosa:', 'Putting', 'Nation', 'over', 'Party', 'Politics', '#nitishkumar', 'supports', 'PM', '@narendramodi', 'on', '#Demonetization', 'https://t.co/UodwXdPMmG']\n",
      "\n",
      "\n",
      " tokenized and lemmatized document: \n",
      "['modibharosa', 'put', 'nation', 'parti', 'polit', 'nitishkumar', 'support', 'narendramodi', 'demonet', 'https', 'uodwxdpmmg']\n"
     ]
    }
   ],
   "source": [
    "doc_sample = documents[documents['index'] == 4000].values[0][0]\n",
    "\n",
    "print('original document: ')\n",
    "words = []\n",
    "for word in doc_sample.split(' '):\n",
    "    words.append(word)\n",
    "print(words)\n",
    "print('\\n\\n tokenized and lemmatized document: ')\n",
    "print(preprocess(doc_sample))\n",
    "#docc=(preprocess(doc_sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying preprocessor on tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_docs = documents['tweet'].astype(str).map(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim import corpora, models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the doc2bow dictionary for words in the dataset and applying the LDA model from gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, '0.112*\"demonet\" + 0.106*\"anilkoh\" + 0.105*\"parti\" + 0.102*\"suffer\" + 0.101*\"loss\" + 0.013*\"https\" + 0.010*\"corrupt\" + 0.009*\"read\" + 0.009*\"hilari\" + 0.009*\"video\"'), (1, '0.090*\"demonet\" + 0.082*\"reaction\" + 0.036*\"https\" + 0.025*\"call\" + 0.024*\"benefit\" + 0.023*\"join\" + 0.021*\"spread\" + 0.021*\"walk\" + 0.021*\"nationalist\" + 0.021*\"joydeep_\"'), (2, '0.118*\"bank\" + 0.117*\"demonet\" + 0.115*\"lakh\" + 0.110*\"terrorist\" + 0.110*\"kishtwar\" + 0.110*\"loot\" + 0.110*\"incid\" + 0.110*\"gauravcsaw\" + 0.003*\"minist\" + 0.002*\"prime\"'), (3, '0.083*\"demonet\" + 0.066*\"https\" + 0.020*\"cash\" + 0.017*\"modi\" + 0.017*\"peopl\" + 0.015*\"take\" + 0.013*\"time\" + 0.012*\"poor\" + 0.011*\"watch\" + 0.011*\"support\"'), (4, '0.085*\"demonet\" + 0.082*\"https\" + 0.081*\"support\" + 0.079*\"parti\" + 0.077*\"narendramodi\" + 0.077*\"polit\" + 0.076*\"nation\" + 0.075*\"nitishkumar\" + 0.074*\"modibharosa\" + 0.074*\"uodwxdpmmg\"'), (5, '0.083*\"demonet\" + 0.082*\"clear\" + 0.079*\"critic\" + 0.078*\"paytm\" + 0.075*\"requir\" + 0.075*\"question\" + 0.075*\"inform\" + 0.074*\"rssurjewala\" + 0.074*\"disclosur\" + 0.074*\"edict\"'), (6, '0.102*\"demonet\" + 0.052*\"narendramodi\" + 0.046*\"address\" + 0.046*\"shashitharoor\" + 0.040*\"understand\" + 0.040*\"parlmnt\" + 0.040*\"duti\" + 0.040*\"frank\" + 0.039*\"anandkam\" + 0.027*\"https\"'), (7, '0.151*\"demonet\" + 0.071*\"go\" + 0.056*\"support\" + 0.053*\"peopl\" + 0.047*\"narendramodi\" + 0.044*\"modibharosa\" + 0.042*\"nation\" + 0.041*\"voter\" + 0.041*\"huge\" + 0.024*\"https\"'), (8, '0.089*\"demonet\" + 0.056*\"https\" + 0.022*\"stand\" + 0.021*\"hear\" + 0.018*\"gandhi\" + 0.018*\"say\" + 0.017*\"nhek\" + 0.016*\"atheist_krishna\" + 0.016*\"explain\" + 0.015*\"tweet\"'), (9, '0.105*\"demonet\" + 0.051*\"survey\" + 0.043*\"https\" + 0.034*\"modi\" + 0.031*\"vote\" + 0.023*\"hemant_\" + 0.022*\"effect\" + 0.019*\"note\" + 0.018*\"support\" + 0.016*\"atheist_krishna\"')]\n"
     ]
    }
   ],
   "source": [
    "wordDict = corpora.Dictionary(processed_docs)\n",
    "docTermMatrix = [wordDict.doc2bow(doc) for doc in processed_docs]\n",
    "Lda = gensim.models.ldamodel.LdaModel\n",
    "model = Lda(docTermMatrix,num_topics=10,id2word=wordDict,passes=100)\n",
    "print(model.print_topics(num_topics=10, num_words=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.080*\"demonet\" + 0.051*\"say\" + 0.034*\"explain\" + 0.031*\"tweet\" + 0.029*\"drgpradhan\" + 0.029*\"prob\" + 0.029*\"have\" + 0.028*\"minimathur\" + 0.028*\"bibi\" + 0.027*\"money\"'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.print_topic(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
